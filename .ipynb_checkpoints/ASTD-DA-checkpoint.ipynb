{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b1b43bd",
   "metadata": {},
   "source": [
    " \n",
    "<img width=\"200px\" height=\"200px\" src='logo-en.png'/>\n",
    "\n",
    "<br/>\n",
    "<div style=\"text-align: center; font-size:20px; font-weight:bold; color: #212F3D\">King Abdullah I School of Graduate Studies and Scientific Research</div><br/>\n",
    "<div style=\"text-align: center; font-size:20px; font-weight:bold; color: #212F3D;\">Data Augmentation using Transformers and Similarity Measures for Improving Arabic Text Classification</div><br/>\n",
    "<div style=\"text-align: center; font-size:14px; font-weight:bold; color: #212F3D\">Dania Refai<sup>1</sup>, Saleh Abu-Soud<sup>2</sup>, Mohammad Abdel-Rahman<sup>3</sup></div>\n",
    "<br/>\n",
    "<div style=\"text-align: left; font-size:14px; font-weight:normal; color: #212F3D\">\n",
    "    <sup>1</sup> Department of Computer Science, Princess Sumaya University for Technology (PSUT), Amman, Jordan</div>\n",
    "<br/>\n",
    "<div style=\"text-align: left; font-size:14px; font-weight:normal; color: #212F3D\">\n",
    "    <sup>2</sup> Department of Data Science, Princess Sumaya University for Technology (PSUT), Amman, Jordan</div>\n",
    "<br/>\n",
    "<div style=\"text-align: left; font-size:14px; font-weight:normal; color: #212F3D\">\n",
    "    <sup>3</sup> Department of Data Science, Princess Sumaya University for Technology (PSUT), Amman, Jordan</div>\n",
    "<br/>\n",
    "\n",
    "<div style=\"text-align: left; font-size:14px; font-weight:bold; color: #212F3D\">\n",
    "        Crosspending author: Dania Refai (<span style=\"text-align: left; font-size:16px; font-weight:bold; color: #6495ED\">Dania.Refai@hotmail.com</span>).\n",
    "</div>\n",
    "<br/>\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9ae633",
   "metadata": {},
   "source": [
    "### <span style=\"text-align: left; font-size:20px; font-weight:bold; color: #C70039\">General Notes and Directions</span> ###\n",
    "<hr/>\n",
    "\n",
    "> <li style=\"text-align: left; font-size:14px; font-weight:bold; color: #212F3D\">&nbsp;Make sure you have pytorch installed on your machine. Moreover, if you want more information please refer to <a href=\"https://pytorch.org/\">INSTALL PYTORCH</a> from their official website.</li>\n",
    "> <li style=\"text-align: left; font-size:14px; font-weight:bold; color: #212F3D\">&nbsp;Make sure your installed python version is 3.8</li>\n",
    "> <li style=\"text-align: left; font-size:14px; font-weight:bold; color: #212F3D\">&nbsp;Make sure you are running the commands INSIDE source code directory (<span style=\"color: #C70039\">.\\Implementation\\</span>)</li>\n",
    "> <li style=\"text-align: left; font-size:14px; font-weight:bold; color: #212F3D\">&nbsp;Run the following commands in your command shell to create and activate a Virtualenv (<span style=\"color: #C70039\">Windows based systems</span>):</li>\n",
    "> <ol>    \n",
    "> <li style=\"text-align: left; font-family:console; font-size:14px; font-weight:bold; color: #212F3D; list-style-type: none;\">\n",
    "       <span style=\"color: #C70039\">cmd&gt;</span> set PATH=C:\\Users\\(<span style=\"text-align: left; font-size:14px; font-weight:bold; color: #C70039\">-windows_user-</span>)\\AppData\\Local\\Programs\\Python\\Python38\\\n",
    "    </li>\n",
    "> <li style=\"text-align: left; font-family:console; font-size:14px; font-weight:bold; color: #212F3D; list-style-type: none;\">\n",
    "       <span style=\"color: #C70039\">cmd&gt;</span> %PATH%\\python.exe -m pip install --upgrade pip\n",
    "    </li>   \n",
    "> <li style=\"text-align: left; font-family:console; font-size:14px; font-weight:bold; color: #212F3D; list-style-type: none;\">\n",
    "       <span style=\"color: #C70039\">cmd&gt;</span> %PATH%python.exe %PATH%Scripts\\pip.exe install virtualenv \n",
    "    </li>    \n",
    "> <li style=\"text-align: left; font-family:console; font-size:14px; font-weight:bold; color: #212F3D; list-style-type: none;\">\n",
    "       <span style=\"color: #C70039\">cmd&gt;</span> %PATH%\\python.exe -m virtualenv venv \n",
    "    </li>\n",
    "> </ol>\n",
    "> <li style=\"text-align: left; font-size:14px; font-weight:bold; color: #212F3D\">&nbsp; Activate the virtual environment: </li>\n",
    "> <ol>    \n",
    "> <li style=\"text-align: left; font-family:console; font-size:14px; font-weight:bold; color: #212F3D; list-style-type: none;\">\n",
    "       <span style=\"color: #C70039\">cmd&gt;</span> .\\venv\\Scripts\\activate\n",
    "    </li>  \n",
    "> </ol>\n",
    "> <li style=\"text-align: left; font-size:14px; font-weight:bold; color: #212F3D\">&nbsp; Install requirements:</li>\n",
    "> <ol>    \n",
    "> <li style=\"text-align: left; font-family:console; font-size:14px; font-weight:bold; color: #212F3D; list-style-type: none;\">\n",
    "       <span style=\"color: #C70039\">cmd&gt;</span> .\\venv\\Scripts\\pip3 install python-dotenv\n",
    "    </li>\n",
    "> <li style=\"text-align: left; font-family:console; font-size:14px; font-weight:bold; color: #212F3D; list-style-type: none;\">\n",
    "       <span style=\"color: #C70039\">cmd&gt;</span> .\\venv\\Scripts\\pip3 install -r requirements.txt\n",
    "    </li>   \n",
    "> </ol>\n",
    "\n",
    "> <li style=\"text-align: left; font-size:14px; font-weight:bold; color: #212F3D\">&nbsp;Notebook Purpose: <span style=\"color: #C70039\">Data Augmentation for ASTD dataset.</span></li>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e08ce2",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a305f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87d916e",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2b6c5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bleu_scores(references, hypotheses):\n",
    "    \"\"\"\n",
    "    Calculates BLEU 1-4 scores based on NLTK functionality\n",
    "\n",
    "    Args:\n",
    "        references: List of reference sentences\n",
    "        hypotheses: List of generated sentences\n",
    "\n",
    "    Returns:\n",
    "        bleu_1, bleu_2, bleu_3, bleu_4: BLEU scores\n",
    "\n",
    "    \"\"\"\n",
    "    #return len(references), len(hypotheses)\n",
    "    bleu_1 = np.round(corpus_bleu(references, hypotheses, weights=(1.0, 0., 0., 0.)), decimals=2)\n",
    "    bleu_2 = np.round(corpus_bleu(references, hypotheses, weights=(0.50, 0.50, 0., 0.)), decimals=2)\n",
    "    bleu_3 = np.round(corpus_bleu(references, hypotheses, weights=(0.34, 0.33, 0.33, 0.)), decimals=2)\n",
    "    bleu_4 = np.round(corpus_bleu(references, hypotheses, weights=(0.25, 0.25, 0.25, 0.25)), decimals=2)\n",
    "    return bleu_1, bleu_2, bleu_3, bleu_4 \n",
    "\n",
    "# Functions\n",
    "def check_label (label):\n",
    "    for lbl in LABEL_TO_AUGMENT:\n",
    "        if lbl.upper() == label.upper():\n",
    "            return True\n",
    "    return False        \n",
    "\n",
    "def check_similarity_cofficient (given_value, label, current_sim_coff):\n",
    "    if not check_label(label):\n",
    "        return False\n",
    "    else:\n",
    "        try:\n",
    "            v = float(given_value)\n",
    "            if float(SIM_COFFICIENTS_THRESHOLDS[current_sim_coff.upper()]) >= v:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        except:\n",
    "            print('exception')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530c455d",
   "metadata": {},
   "source": [
    "### Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d174e3dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>new_text</th>\n",
       "      <th>all_text</th>\n",
       "      <th>original_embbedding</th>\n",
       "      <th>new_embbedding</th>\n",
       "      <th>ecu_similarity</th>\n",
       "      <th>cos_similarity</th>\n",
       "      <th>jacc_similarity</th>\n",
       "      <th>text_split</th>\n",
       "      <th>all_text_split</th>\n",
       "      <th>new_text_split</th>\n",
       "      <th>bleu_sim_1</th>\n",
       "      <th>bleu_sim_2</th>\n",
       "      <th>bleu_sim_3</th>\n",
       "      <th>bleu_sim_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5 هاتلي اخوان أي حاجة مش تنوين ومش ضمير اخوان ...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>!!.</td>\n",
       "      <td>5 هاتلي اخوان أي حاجة مش تنوين ومش ضمير اخوان ...</td>\n",
       "      <td>0.014882844,-0.051557414,-0.028316082,0.014168...</td>\n",
       "      <td>0.01946623,-0.010952667,-0.039843258,-0.057320...</td>\n",
       "      <td>0.772223</td>\n",
       "      <td>0.446</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>['5', 'هاتلي', 'اخوان', 'أي', 'حاجة', 'مش', 'ت...</td>\n",
       "      <td>['5', 'هاتلي', 'اخوان', 'أي', 'حاجة', 'مش', 'ت...</td>\n",
       "      <td>['!!.']</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>دباسم يوسف عمل برنامج البرنامج و #فسسسسسس</td>\n",
       "      <td>NEG</td>\n",
       "      <td>لر على # الفيس _ بوك [رابط]بسم الله الرحمن الر...</td>\n",
       "      <td>دباسم يوسف عمل برنامج البرنامج و # فسسلر على #...</td>\n",
       "      <td>0.016909812,0.015640503,-0.02446039,-0.0235670...</td>\n",
       "      <td>0.017838204,0.007064947,-0.03709342,-0.0264731...</td>\n",
       "      <td>0.205765</td>\n",
       "      <td>0.929</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>['دباسم', 'يوسف', 'عمل', 'برنامج', 'البرنامج',...</td>\n",
       "      <td>['دباسم', 'يوسف', 'عمل', 'برنامج', 'البرنامج',...</td>\n",
       "      <td>['لر', 'على', '#', 'الفيس', '_', 'بوك', '[رابط...</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>منذ عامين وحتى الآن كل ما قدمه أنصار تيارات ال...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>.</td>\n",
       "      <td>منذ عامين وحتى الآن كل ما قدمه أنصار تيارات ال...</td>\n",
       "      <td>0.026780926,0.009709039,-0.030822175,-0.033138...</td>\n",
       "      <td>0.022658788,-0.0036188036,-0.033782676,-0.0437...</td>\n",
       "      <td>0.237325</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>['منذ', 'عامين', 'وحتى', 'الآن', 'كل', 'ما', '...</td>\n",
       "      <td>['منذ', 'عامين', 'وحتى', 'الآن', 'كل', 'ما', '...</td>\n",
       "      <td>['.']</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#السعاده ان يكون من نحب بخير وعافيه فنحن نشعر ...</td>\n",
       "      <td>POS</td>\n",
       "      <td>.</td>\n",
       "      <td># السعاده ان يكون من نحب بخير وعافيه فنحن نشعر...</td>\n",
       "      <td>0.011575715,-0.0191376,-0.041333534,-0.0137087...</td>\n",
       "      <td>0.022658788,-0.0036188036,-0.033782676,-0.0437...</td>\n",
       "      <td>0.352307</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>['#السعاده', 'ان', 'يكون', 'من', 'نحب', 'بخير'...</td>\n",
       "      <td>['#', 'السعاده', 'ان', 'يكون', 'من', 'نحب', 'ب...</td>\n",
       "      <td>['.']</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>درية شرف الدين امرأة على الوشين لا مهنية ولا ا...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>في الشوارع.</td>\n",
       "      <td>درية شرف الدين امرأة على الوشين لا مهنية ولا ا...</td>\n",
       "      <td>0.016909812,0.015640503,-0.02446039,-0.0235670...</td>\n",
       "      <td>0.017580768,-0.0027376027,-0.03825421,-0.04189...</td>\n",
       "      <td>0.390541</td>\n",
       "      <td>0.834</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>['درية', 'شرف', 'الدين', 'امرأة', 'على', 'الوش...</td>\n",
       "      <td>['درية', 'شرف', 'الدين', 'امرأة', 'على', 'الوش...</td>\n",
       "      <td>['في', 'الشوارع.']</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label   \n",
       "0  5 هاتلي اخوان أي حاجة مش تنوين ومش ضمير اخوان ...   NEG  \\\n",
       "1          دباسم يوسف عمل برنامج البرنامج و #فسسسسسس   NEG   \n",
       "2  منذ عامين وحتى الآن كل ما قدمه أنصار تيارات ال...   NEG   \n",
       "3  #السعاده ان يكون من نحب بخير وعافيه فنحن نشعر ...   POS   \n",
       "4  درية شرف الدين امرأة على الوشين لا مهنية ولا ا...   NEG   \n",
       "\n",
       "                                            new_text   \n",
       "0                                                !!.  \\\n",
       "1  لر على # الفيس _ بوك [رابط]بسم الله الرحمن الر...   \n",
       "2                                                  .   \n",
       "3                                                  .   \n",
       "4                                        في الشوارع.   \n",
       "\n",
       "                                            all_text   \n",
       "0  5 هاتلي اخوان أي حاجة مش تنوين ومش ضمير اخوان ...  \\\n",
       "1  دباسم يوسف عمل برنامج البرنامج و # فسسلر على #...   \n",
       "2  منذ عامين وحتى الآن كل ما قدمه أنصار تيارات ال...   \n",
       "3  # السعاده ان يكون من نحب بخير وعافيه فنحن نشعر...   \n",
       "4  درية شرف الدين امرأة على الوشين لا مهنية ولا ا...   \n",
       "\n",
       "                                 original_embbedding   \n",
       "0  0.014882844,-0.051557414,-0.028316082,0.014168...  \\\n",
       "1  0.016909812,0.015640503,-0.02446039,-0.0235670...   \n",
       "2  0.026780926,0.009709039,-0.030822175,-0.033138...   \n",
       "3  0.011575715,-0.0191376,-0.041333534,-0.0137087...   \n",
       "4  0.016909812,0.015640503,-0.02446039,-0.0235670...   \n",
       "\n",
       "                                      new_embbedding  ecu_similarity   \n",
       "0  0.01946623,-0.010952667,-0.039843258,-0.057320...        0.772223  \\\n",
       "1  0.017838204,0.007064947,-0.03709342,-0.0264731...        0.205765   \n",
       "2  0.022658788,-0.0036188036,-0.033782676,-0.0437...        0.237325   \n",
       "3  0.022658788,-0.0036188036,-0.033782676,-0.0437...        0.352307   \n",
       "4  0.017580768,-0.0027376027,-0.03825421,-0.04189...        0.390541   \n",
       "\n",
       "   cos_similarity  jacc_similarity   \n",
       "0           0.446         0.037037  \\\n",
       "1           0.929         0.437500   \n",
       "2           0.904         0.000000   \n",
       "3           0.829         0.000000   \n",
       "4           0.834         0.360000   \n",
       "\n",
       "                                          text_split   \n",
       "0  ['5', 'هاتلي', 'اخوان', 'أي', 'حاجة', 'مش', 'ت...  \\\n",
       "1  ['دباسم', 'يوسف', 'عمل', 'برنامج', 'البرنامج',...   \n",
       "2  ['منذ', 'عامين', 'وحتى', 'الآن', 'كل', 'ما', '...   \n",
       "3  ['#السعاده', 'ان', 'يكون', 'من', 'نحب', 'بخير'...   \n",
       "4  ['درية', 'شرف', 'الدين', 'امرأة', 'على', 'الوش...   \n",
       "\n",
       "                                      all_text_split   \n",
       "0  ['5', 'هاتلي', 'اخوان', 'أي', 'حاجة', 'مش', 'ت...  \\\n",
       "1  ['دباسم', 'يوسف', 'عمل', 'برنامج', 'البرنامج',...   \n",
       "2  ['منذ', 'عامين', 'وحتى', 'الآن', 'كل', 'ما', '...   \n",
       "3  ['#', 'السعاده', 'ان', 'يكون', 'من', 'نحب', 'ب...   \n",
       "4  ['درية', 'شرف', 'الدين', 'امرأة', 'على', 'الوش...   \n",
       "\n",
       "                                      new_text_split  bleu_sim_1  bleu_sim_2   \n",
       "0                                            ['!!.']        0.89        0.89  \\\n",
       "1  ['لر', 'على', '#', 'الفيس', '_', 'بوك', '[رابط...        0.14        0.13   \n",
       "2                                              ['.']        0.95        0.95   \n",
       "3                                              ['.']        0.79        0.78   \n",
       "4                                 ['في', 'الشوارع.']        0.92        0.92   \n",
       "\n",
       "   bleu_sim_3  bleu_sim_4  \n",
       "0        0.88        0.88  \n",
       "1        0.12        0.11  \n",
       "2        0.95        0.95  \n",
       "3        0.78        0.77  \n",
       "4        0.92        0.92  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasetname = 'ASTD'\n",
    "datasetpath = \"datasets/xls/ASTD-Unbalanced-Augmented-aragpt2-base.csv\"\n",
    "df = pd.read_csv( datasetpath, sep=\"\\t\", encoding='utf-8')\n",
    "df.columns = ['text', 'label', 'new_text', 'all_text', 'original_embbedding', 'new_embbedding', 'ecu_similarity', 'cos_similarity', 'jacc_similarity','text_split', 'all_text_split', 'new_text_split', 'bleu_sim_1','bleu_sim_2', 'bleu_sim_3', 'bleu_sim_4'] \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0899ad97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "NEG        1640\n",
       "NEUTRAL     805\n",
       "POS         776\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dda79d",
   "metadata": {},
   "source": [
    "### Calculating Similarity Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e5c01fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_split'] = [list(x.split()) for x in df['text']]\n",
    "df['all_text_split'] = [x.split() for x in df['all_text']]\n",
    "df['new_text_split'] = [str(x).split() for x in df['new_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cdddcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    " df[['bleu_sim_1','bleu_sim_2','bleu_sim_3','bleu_sim_4']] = [ calculate_bleu_scores ([[x]],[y]) for x, y in zip(df['text_split'], df['all_text_split'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6a9ed2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bleu_sim_1</th>\n",
       "      <th>bleu_sim_1</th>\n",
       "      <th>bleu_sim_1</th>\n",
       "      <th>bleu_sim_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3216</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3217</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3218</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3219</th>\n",
       "      <td>0.13</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3220</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3221 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      bleu_sim_1  bleu_sim_1  bleu_sim_1  bleu_sim_1\n",
       "0           0.89        0.89        0.89        0.89\n",
       "1           0.14        0.14        0.14        0.14\n",
       "2           0.95        0.95        0.95        0.95\n",
       "3           0.79        0.79        0.79        0.79\n",
       "4           0.92        0.92        0.92        0.92\n",
       "...          ...         ...         ...         ...\n",
       "3216        0.76        0.76        0.76        0.76\n",
       "3217        0.74        0.74        0.74        0.74\n",
       "3218        0.02        0.02        0.02        0.02\n",
       "3219        0.13        0.13        0.13        0.13\n",
       "3220        0.75        0.75        0.75        0.75\n",
       "\n",
       "[3221 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " df[['bleu_sim_1','bleu_sim_1','bleu_sim_1','bleu_sim_1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5acb47f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33158923031772564"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"ecu_similarity\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1972913b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8526818791946309"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"cos_similarity\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db8ca37c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3624915367325659"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"jacc_similarity\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6292c4fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3949177274138466"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"bleu_sim_1\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd88e664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "all_datasets= []\n",
    "SIM_COFFICIENTS_THRESHOLDS = {'ECU': df[\"ecu_similarity\"].mean(), 'COS':df[\"cos_similarity\"].mean(), 'JAC':df[\"jacc_similarity\"].mean(), 'BLEU':df[\"bleu_sim_1\"].mean()}\n",
    "LABEL_TO_AUGMENT = ['POS', 'NEUTRAL']\n",
    "DATA_COLUMN = \"text\"\n",
    "LABEL_COLUMN = \"label\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "722bdb44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ECU': 0.33158923031772564,\n",
       " 'COS': 0.8526818791946309,\n",
       " 'JAC': 0.3624915367325659,\n",
       " 'BLEU': 0.3949177274138466}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SIM_COFFICIENTS_THRESHOLDS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4209c45e",
   "metadata": {},
   "source": [
    "### Augmentation (All-Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c653b89d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All text augmentation is started... \n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m Jac_value \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjacc_similarity\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     13\u001b[0m Bleu_value \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbleu_sim_1\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 15\u001b[0m EcuDF \u001b[38;5;241m=\u001b[39m \u001b[43mEcuDF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m(tmpDF, ignore_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     16\u001b[0m CosDF \u001b[38;5;241m=\u001b[39m CosDF\u001b[38;5;241m.\u001b[39mappend(tmpDF, ignore_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     17\u001b[0m JacDF \u001b[38;5;241m=\u001b[39m JacDF\u001b[38;5;241m.\u001b[39mappend(tmpDF, ignore_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\generic.py:5989\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5982\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   5983\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[0;32m   5984\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[0;32m   5985\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[0;32m   5986\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   5987\u001b[0m ):\n\u001b[0;32m   5988\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[1;32m-> 5989\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "EcuDF = pd.DataFrame()\n",
    "CosDF = pd.DataFrame()\n",
    "JacDF = pd.DataFrame()\n",
    "BleDF = pd.DataFrame()\n",
    "cntr = 1\n",
    "\n",
    "print('All text augmentation is started... ')\n",
    "for index, row in df.iterrows():         \n",
    "    tmpDF = { 'text': row[DATA_COLUMN], 'label': row[LABEL_COLUMN]}\n",
    "    Ecu_value = row['ecu_similarity']\n",
    "    Cos_value = row['cos_similarity']\n",
    "    Jac_value = row['jacc_similarity']\n",
    "    Bleu_value = row['bleu_sim_1']\n",
    "    \n",
    "    EcuDF = EcuDF.append(tmpDF, ignore_index = True)\n",
    "    CosDF = CosDF.append(tmpDF, ignore_index = True)\n",
    "    JacDF = JacDF.append(tmpDF, ignore_index = True)\n",
    "    BleDF = BleDF.append(tmpDF, ignore_index=True)\n",
    "    \n",
    "    tmpDF = { 'text': row['all_text'], 'label': row[LABEL_COLUMN]}\n",
    "    # Check similarity \n",
    "    if check_similarity_cofficient (Ecu_value, row[LABEL_COLUMN], 'ecu'):\n",
    "        EcuDF = EcuDF.append(tmpDF, ignore_index = True)\n",
    "    \n",
    "    if check_similarity_cofficient (Cos_value, row[LABEL_COLUMN], 'cos'):\n",
    "        CosDF = CosDF.append(tmpDF, ignore_index = True)\n",
    "    \n",
    "    if check_similarity_cofficient (Jac_value, row[LABEL_COLUMN], 'jac'):\n",
    "        JacDF = JacDF.append(tmpDF, ignore_index = True)\n",
    "    \n",
    "    if check_similarity_cofficient (Bleu_value, row[LABEL_COLUMN], 'bleu'):\n",
    "        BleDF = BleDF.append(tmpDF, ignore_index = True)\n",
    "        \n",
    "print('All text augmentation is finished ... ')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d12cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export dataset\n",
    "EcuDF.to_excel( \"Augmented-Dataset/All/\"+datasetname+\"-Augmented-ECU-ALL-Text-Final.xlsx\", encoding='utf-8', index=False)\n",
    "CosDF.to_excel( \"Augmented-Dataset/All/\"+datasetname+\"-Augmented-COS-ALL-Text-Final.xlsx\", encoding='utf-8', index=False)\n",
    "JacDF.to_excel( \"Augmented-Dataset/All/\"+datasetname+\"-Augmented-JAC-ALL-Text-Final.xlsx\", encoding='utf-8', index=False)\n",
    "BleDF.to_excel( \"Augmented-Dataset/All/\"+datasetname+\"-Augmented-BLE-ALL-Text-Final.xlsx\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ee996d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel( \"Augmented-Dataset/xls/ASTD-Unbalanced-Augmented-aragpt2-base.xlsx\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a48b20",
   "metadata": {},
   "source": [
    "### Augmentation (New-Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a9fff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "EcuDF = pd.DataFrame()\n",
    "CosDF = pd.DataFrame()\n",
    "JacDF = pd.DataFrame()\n",
    "BleDF = pd.DataFrame()\n",
    "cntr = 1\n",
    "\n",
    "print('new text augmentation is started... ')\n",
    "for index, row in df.iterrows():         \n",
    "    tmpDF = { 'text': row[DATA_COLUMN], 'label': row[LABEL_COLUMN]}\n",
    "    Ecu_value = row['ecu_similarity']\n",
    "    Cos_value = row['cos_similarity']\n",
    "    Jac_value = row['jacc_similarity']\n",
    "    Bleu_value = row['bleu_sim_1']\n",
    "    \n",
    "    EcuDF = EcuDF.append(tmpDF, ignore_index = True)\n",
    "    CosDF = CosDF.append(tmpDF, ignore_index = True)\n",
    "    JacDF = JacDF.append(tmpDF, ignore_index = True)\n",
    "    BleDF = BleDF.append(tmpDF, ignore_index=True)\n",
    "    \n",
    "    tmpDF = { 'text': row['new_text'], 'label': row[LABEL_COLUMN]}\n",
    "    # Check similarity \n",
    "    if check_similarity_cofficient (Ecu_value, row[LABEL_COLUMN], 'ecu'):\n",
    "        EcuDF = EcuDF.append(tmpDF, ignore_index = True)\n",
    "    \n",
    "    if check_similarity_cofficient (Cos_value, row[LABEL_COLUMN], 'cos'):\n",
    "        CosDF = CosDF.append(tmpDF, ignore_index = True)\n",
    "    \n",
    "    if check_similarity_cofficient (Jac_value, row[LABEL_COLUMN], 'jac'):\n",
    "        JacDF = JacDF.append(tmpDF, ignore_index = True)\n",
    "    \n",
    "    if check_similarity_cofficient (Bleu_value, row[LABEL_COLUMN], 'bleu'):\n",
    "        BleDF = BleDF.append(tmpDF, ignore_index = True)\n",
    "        \n",
    "print('new text augmentation is finished ... ')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d220ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export dataset\n",
    "EcuDF.to_excel( \"Augmented-Dataset/New/\"+datasetname+\"-Augmented-ECU-New-Text-Final.xlsx\", encoding='utf-8', index=False)\n",
    "CosDF.to_excel( \"Augmented-Dataset/New/\"+datasetname+\"-Augmented-COS-New-Text-Final.xlsx\", encoding='utf-8', index=False)\n",
    "JacDF.to_excel( \"Augmented-Dataset/New/\"+datasetname+\"-Augmented-JAC-New-Text-Final.xlsx\", encoding='utf-8', index=False)\n",
    "BleDF.to_excel( \"Augmented-Dataset/New/\"+datasetname+\"-Augmented-BLE-New-Text-Final.xlsx\", encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
