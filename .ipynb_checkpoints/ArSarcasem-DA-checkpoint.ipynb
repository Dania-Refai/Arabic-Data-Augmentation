{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97dd7736",
   "metadata": {},
   "source": [
    " \n",
    "<img width=\"200px\" height=\"200px\" src='logo-en.png'/>\n",
    "\n",
    "<br/>\n",
    "<div style=\"text-align: center; font-size:20px; font-weight:bold; color: #212F3D\">King Abdullah I School of Graduate Studies and Scientific Research</div><br/>\n",
    "<div style=\"text-align: center; font-size:20px; font-weight:bold; color: #212F3D;\">Data Augmentation using Transformers and Similarity Measures for Improving Arabic Text Classification</div><br/>\n",
    "<div style=\"text-align: center; font-size:14px; font-weight:bold; color: #212F3D\">Dania Refai<sup>1</sup>, Saleh Abu-Soud<sup>2</sup>, Mohammad Abdel-Rahman<sup>3</sup></div>\n",
    "<br/>\n",
    "<div style=\"text-align: left; font-size:14px; font-weight:normal; color: #212F3D\">\n",
    "    <sup>1</sup> Department of Computer Science, Princess Sumaya University for Technology (PSUT), Amman, Jordan</div>\n",
    "<br/>\n",
    "<div style=\"text-align: left; font-size:14px; font-weight:normal; color: #212F3D\">\n",
    "    <sup>2</sup> Department of Data Science, Princess Sumaya University for Technology (PSUT), Amman, Jordan</div>\n",
    "<br/>\n",
    "<div style=\"text-align: left; font-size:14px; font-weight:normal; color: #212F3D\">\n",
    "    <sup>3</sup> Department of Data Science, Princess Sumaya University for Technology (PSUT), Amman, Jordan</div>\n",
    "<br/>\n",
    "\n",
    "<div style=\"text-align: left; font-size:14px; font-weight:bold; color: #212F3D\">\n",
    "        Crosspending author: Dania Refai (<span style=\"text-align: left; font-size:16px; font-weight:bold; color: #6495ED\">Dania.Refai@hotmail.com</span>).\n",
    "</div>\n",
    "<br/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7639d1d1",
   "metadata": {},
   "source": [
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eec56dc",
   "metadata": {},
   "source": [
    "### <span style=\"text-align: left; font-size:20px; font-weight:bold; color: #C70039\">General Notes and Directions</span> ###\n",
    "<hr/>\n",
    "\n",
    "> <li style=\"text-align: left; font-size:14px; font-weight:bold; color: #212F3D\">&nbsp;Make sure you have pytorch installed on your machine. Moreover, if you want more information please refer to <a href=\"https://pytorch.org/\">INSTALL PYTORCH</a> from their official website.</li>\n",
    "> <li style=\"text-align: left; font-size:14px; font-weight:bold; color: #212F3D\">&nbsp;Make sure your installed python version is 3.8</li>\n",
    "> <li style=\"text-align: left; font-size:14px; font-weight:bold; color: #212F3D\">&nbsp;Make sure you are running the commands INSIDE source code directory (<span style=\"color: #C70039\">.\\Implementation\\</span>)</li>\n",
    "> <li style=\"text-align: left; font-size:14px; font-weight:bold; color: #212F3D\">&nbsp;Run the following commands in your command shell to create and activate a Virtualenv (<span style=\"color: #C70039\">Windows based systems</span>):</li>\n",
    "> <ol>    \n",
    "> <li style=\"text-align: left; font-family:console; font-size:14px; font-weight:bold; color: #212F3D; list-style-type: none;\">\n",
    "       <span style=\"color: #C70039\">cmd&gt;</span> set PATH=C:\\Users\\(<span style=\"text-align: left; font-size:14px; font-weight:bold; color: #C70039\">-windows_user-</span>)\\AppData\\Local\\Programs\\Python\\Python38\\\n",
    "    </li>\n",
    "> <li style=\"text-align: left; font-family:console; font-size:14px; font-weight:bold; color: #212F3D; list-style-type: none;\">\n",
    "       <span style=\"color: #C70039\">cmd&gt;</span> %PATH%\\python.exe -m pip install --upgrade pip\n",
    "    </li>   \n",
    "> <li style=\"text-align: left; font-family:console; font-size:14px; font-weight:bold; color: #212F3D; list-style-type: none;\">\n",
    "       <span style=\"color: #C70039\">cmd&gt;</span> %PATH%python.exe %PATH%Scripts\\pip.exe install virtualenv \n",
    "    </li>    \n",
    "> <li style=\"text-align: left; font-family:console; font-size:14px; font-weight:bold; color: #212F3D; list-style-type: none;\">\n",
    "       <span style=\"color: #C70039\">cmd&gt;</span> %PATH%\\python.exe -m virtualenv venv \n",
    "    </li>\n",
    "> </ol>\n",
    "> <li style=\"text-align: left; font-size:14px; font-weight:bold; color: #212F3D\">&nbsp; Activate the virtual environment: </li>\n",
    "> <ol>    \n",
    "> <li style=\"text-align: left; font-family:console; font-size:14px; font-weight:bold; color: #212F3D; list-style-type: none;\">\n",
    "       <span style=\"color: #C70039\">cmd&gt;</span> .\\venv\\Scripts\\activate\n",
    "    </li>  \n",
    "> </ol>\n",
    "> <li style=\"text-align: left; font-size:14px; font-weight:bold; color: #212F3D\">&nbsp; Install requirements:</li>\n",
    "> <ol>    \n",
    "> <li style=\"text-align: left; font-family:console; font-size:14px; font-weight:bold; color: #212F3D; list-style-type: none;\">\n",
    "       <span style=\"color: #C70039\">cmd&gt;</span> .\\venv\\Scripts\\pip3 install python-dotenv\n",
    "    </li>\n",
    "> <li style=\"text-align: left; font-family:console; font-size:14px; font-weight:bold; color: #212F3D; list-style-type: none;\">\n",
    "       <span style=\"color: #C70039\">cmd&gt;</span> .\\venv\\Scripts\\pip3 install -r requirements.txt\n",
    "    </li>   \n",
    "> </ol>\n",
    "\n",
    "> <li style=\"text-align: left; font-size:14px; font-weight:bold; color: #212F3D\">&nbsp;Notebook Purpose: <span style=\"color: #C70039\">Data Augmentation for ArSarcasem-DA dataset.</span></li>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b11e6d1",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a305f7d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtranslate\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbleu_score\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sentence_bleu\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bdf1d3",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c80e9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bleu_scores(references, hypotheses):\n",
    "    \"\"\"\n",
    "    Calculates BLEU 1-4 scores based on NLTK functionality\n",
    "\n",
    "    Args:\n",
    "        references: List of reference sentences\n",
    "        hypotheses: List of generated sentences\n",
    "\n",
    "    Returns:\n",
    "        bleu_1, bleu_2, bleu_3, bleu_4: BLEU scores\n",
    "\n",
    "    \"\"\"\n",
    "    #return len(references), len(hypotheses)\n",
    "    bleu_1 = np.round(corpus_bleu(references, hypotheses, weights=(1.0, 0., 0., 0.)), decimals=2)\n",
    "    bleu_2 = np.round(corpus_bleu(references, hypotheses, weights=(0.50, 0.50, 0., 0.)), decimals=2)\n",
    "    bleu_3 = np.round(corpus_bleu(references, hypotheses, weights=(0.34, 0.33, 0.33, 0.)), decimals=2)\n",
    "    bleu_4 = np.round(corpus_bleu(references, hypotheses, weights=(0.25, 0.25, 0.25, 0.25)), decimals=2)\n",
    "    return bleu_1, bleu_2, bleu_3, bleu_4 \n",
    "\n",
    "# Functions\n",
    "def check_label (label):\n",
    "    for lbl in LABEL_TO_AUGMENT:\n",
    "        if lbl.upper() == label.upper():\n",
    "            return True\n",
    "    return False        \n",
    "\n",
    "def check_similarity_cofficient (given_value, label, current_sim_coff):\n",
    "    if not check_label(label):\n",
    "        return False\n",
    "    else:\n",
    "        try:\n",
    "            v = float(given_value)\n",
    "            if float(SIM_COFFICIENTS_THRESHOLDS[current_sim_coff.upper()]) >= v:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        except:\n",
    "            print('exception')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923a3bf9",
   "metadata": {},
   "source": [
    "### Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9751ea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>new_text</th>\n",
       "      <th>all_text</th>\n",
       "      <th>original_embbedding</th>\n",
       "      <th>new_embbedding</th>\n",
       "      <th>ecu_similarity</th>\n",
       "      <th>cos_similarity</th>\n",
       "      <th>jacc_similarity</th>\n",
       "      <th>text_split</th>\n",
       "      <th>all_text_split</th>\n",
       "      <th>new_text_split</th>\n",
       "      <th>bleu_sim_1</th>\n",
       "      <th>bleu_sim_2</th>\n",
       "      <th>bleu_sim_3</th>\n",
       "      <th>bleu_sim_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"@Alito_NBA اتوقع انه بيستمر\"</td>\n",
       "      <td>neutral</td>\n",
       "      <td>.</td>\n",
       "      <td>[بريد] اتوقع انه بيستمر \".</td>\n",
       "      <td>0.016990522,-0.01140931,-0.028880069,-0.041880...</td>\n",
       "      <td>0.022658788,-0.0036188036,-0.033782676,-0.0437...</td>\n",
       "      <td>0.455610</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>['\"@Alito_NBA', 'اتوقع', 'انه', 'بيستمر\"']</td>\n",
       "      <td>['[بريد]', 'اتوقع', 'انه', 'بيستمر', '\".']</td>\n",
       "      <td>['.']</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"@KSA24 يعني \"بموافقتنا\" لأن دمشق صايرة موسكو\"</td>\n",
       "      <td>neutral</td>\n",
       "      <td>.</td>\n",
       "      <td>[بريد] يعني \" بموافقتنا \" لأن دمشق صايرة موسكو \".</td>\n",
       "      <td>0.01699051,-0.011409308,-0.028880073,-0.041880...</td>\n",
       "      <td>0.022658788,-0.0036188036,-0.033782676,-0.0437...</td>\n",
       "      <td>0.455610</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>['\"@KSA24', 'يعني', '\"بموافقتنا\"', 'لأن', 'دمش...</td>\n",
       "      <td>['[بريد]', 'يعني', '\"', 'بموافقتنا', '\"', 'لأن...</td>\n",
       "      <td>['.']</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"RT @alaahmad20: قائد في الحرس يعترف بفقدان ال...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>…</td>\n",
       "      <td>\" RT [مستخدم] : قائد في الحرس يعترف بفقدان الس...</td>\n",
       "      <td>0.021876294,0.006824673,-0.037487492,-0.028356...</td>\n",
       "      <td>0.01758077,-0.002737612,-0.038254194,-0.041899...</td>\n",
       "      <td>0.400617</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>['\"RT', '@alaahmad20:', 'قائد', 'في', 'الحرس',...</td>\n",
       "      <td>['\"', 'RT', '[مستخدم]', ':', 'قائد', 'في', 'ال...</td>\n",
       "      <td>['…']</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>شوال الفلوس سويرس مشغول اوى اليومين دول بقناة ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>..</td>\n",
       "      <td>شوال الفلوس سويرس مشغول اوى اليومين دول بقناة ...</td>\n",
       "      <td>0.021415915,0.034925364,-0.036916047,-0.010989...</td>\n",
       "      <td>0.022658788,-0.0036188036,-0.033782683,-0.0437...</td>\n",
       "      <td>0.419766</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>['شوال', 'الفلوس', 'سويرس', 'مشغول', 'اوى', 'ا...</td>\n",
       "      <td>['شوال', 'الفلوس', 'سويرس', 'مشغول', 'اوى', 'ا...</td>\n",
       "      <td>['..']</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"الأمين العام للأمم المتحدة: بشار الأسد قتل 30...</td>\n",
       "      <td>negative</td>\n",
       "      <td>منظمة الأمن والتعاون في أوروبا : الحرب مع تنظ...</td>\n",
       "      <td>\" الأمين العام للأمم المتحدة : بشار الأسد قتل ...</td>\n",
       "      <td>0.021876294,0.006824673,-0.037487492,-0.028356...</td>\n",
       "      <td>0.017580774,-0.0027376045,-0.03825421,-0.04189...</td>\n",
       "      <td>0.400617</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>['\"الأمين', 'العام', 'للأمم', 'المتحدة:', 'بشا...</td>\n",
       "      <td>['\"', 'الأمين', 'العام', 'للأمم', 'المتحدة', '...</td>\n",
       "      <td>['منظمة', 'الأمن', 'والتعاون', 'في', 'أوروبا',...</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     label  \\\n",
       "0                      \"@Alito_NBA اتوقع انه بيستمر\"   neutral   \n",
       "1     \"@KSA24 يعني \"بموافقتنا\" لأن دمشق صايرة موسكو\"   neutral   \n",
       "2  \"RT @alaahmad20: قائد في الحرس يعترف بفقدان ال...   neutral   \n",
       "3  شوال الفلوس سويرس مشغول اوى اليومين دول بقناة ...  negative   \n",
       "4  \"الأمين العام للأمم المتحدة: بشار الأسد قتل 30...  negative   \n",
       "\n",
       "                                            new_text  \\\n",
       "0                                                  .   \n",
       "1                                                  .   \n",
       "2                                                  …   \n",
       "3                                                 ..   \n",
       "4   منظمة الأمن والتعاون في أوروبا : الحرب مع تنظ...   \n",
       "\n",
       "                                            all_text  \\\n",
       "0                         [بريد] اتوقع انه بيستمر \".   \n",
       "1  [بريد] يعني \" بموافقتنا \" لأن دمشق صايرة موسكو \".   \n",
       "2  \" RT [مستخدم] : قائد في الحرس يعترف بفقدان الس...   \n",
       "3  شوال الفلوس سويرس مشغول اوى اليومين دول بقناة ...   \n",
       "4  \" الأمين العام للأمم المتحدة : بشار الأسد قتل ...   \n",
       "\n",
       "                                 original_embbedding  \\\n",
       "0  0.016990522,-0.01140931,-0.028880069,-0.041880...   \n",
       "1  0.01699051,-0.011409308,-0.028880073,-0.041880...   \n",
       "2  0.021876294,0.006824673,-0.037487492,-0.028356...   \n",
       "3  0.021415915,0.034925364,-0.036916047,-0.010989...   \n",
       "4  0.021876294,0.006824673,-0.037487492,-0.028356...   \n",
       "\n",
       "                                      new_embbedding  ecu_similarity  \\\n",
       "0  0.022658788,-0.0036188036,-0.033782676,-0.0437...        0.455610   \n",
       "1  0.022658788,-0.0036188036,-0.033782676,-0.0437...        0.455610   \n",
       "2  0.01758077,-0.002737612,-0.038254194,-0.041899...        0.400617   \n",
       "3  0.022658788,-0.0036188036,-0.033782683,-0.0437...        0.419766   \n",
       "4  0.017580774,-0.0027376045,-0.03825421,-0.04189...        0.400617   \n",
       "\n",
       "   cos_similarity  jacc_similarity  \\\n",
       "0           0.762         0.000000   \n",
       "1           0.762         0.000000   \n",
       "2           0.824         0.029412   \n",
       "3           0.800         0.000000   \n",
       "4           0.824         0.600000   \n",
       "\n",
       "                                          text_split  \\\n",
       "0         ['\"@Alito_NBA', 'اتوقع', 'انه', 'بيستمر\"']   \n",
       "1  ['\"@KSA24', 'يعني', '\"بموافقتنا\"', 'لأن', 'دمش...   \n",
       "2  ['\"RT', '@alaahmad20:', 'قائد', 'في', 'الحرس',...   \n",
       "3  ['شوال', 'الفلوس', 'سويرس', 'مشغول', 'اوى', 'ا...   \n",
       "4  ['\"الأمين', 'العام', 'للأمم', 'المتحدة:', 'بشا...   \n",
       "\n",
       "                                      all_text_split  \\\n",
       "0         ['[بريد]', 'اتوقع', 'انه', 'بيستمر', '\".']   \n",
       "1  ['[بريد]', 'يعني', '\"', 'بموافقتنا', '\"', 'لأن...   \n",
       "2  ['\"', 'RT', '[مستخدم]', ':', 'قائد', 'في', 'ال...   \n",
       "3  ['شوال', 'الفلوس', 'سويرس', 'مشغول', 'اوى', 'ا...   \n",
       "4  ['\"', 'الأمين', 'العام', 'للأمم', 'المتحدة', '...   \n",
       "\n",
       "                                      new_text_split  bleu_sim_1  bleu_sim_2  \\\n",
       "0                                              ['.']        0.40        0.32   \n",
       "1                                              ['.']        0.40        0.30   \n",
       "2                                              ['…']        0.48        0.47   \n",
       "3                                             ['..']        0.95        0.95   \n",
       "4  ['منظمة', 'الأمن', 'والتعاون', 'في', 'أوروبا',...        0.06        0.05   \n",
       "\n",
       "   bleu_sim_3  bleu_sim_4  \n",
       "0        0.00        0.00  \n",
       "1        0.22        0.00  \n",
       "2        0.46        0.44  \n",
       "3        0.94        0.94  \n",
       "4        0.05        0.04  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasetname = 'ArSarcasem'\n",
    "datasetpath = \"datasets/xls/ArSarcasm-Unbalanced-Augmented-aragpt2-base.csv\"\n",
    "df = pd.read_csv( datasetpath, sep=\"\\t\", encoding='utf-8')\n",
    "df.columns = ['text', 'label', 'new_text', 'all_text', 'original_embbedding', 'new_embbedding', 'ecu_similarity', 'cos_similarity', 'jacc_similarity','text_split', 'all_text_split', 'new_text_split', 'bleu_sim_1','bleu_sim_2', 'bleu_sim_3', 'bleu_sim_4'] \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0899ad97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     5339\n",
       "negative    3528\n",
       "positive    1678\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d118bba",
   "metadata": {},
   "source": [
    "### Calculating Similarity Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e5c01fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_split'] = [list(x.split()) for x in df['text']]\n",
    "df['all_text_split'] = [x.split() for x in df['all_text']]\n",
    "df['new_text_split'] = [str(x).split() for x in df['new_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cdddcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    " df[['bleu_sim_1','bleu_sim_2','bleu_sim_3','bleu_sim_4']] = [ calculate_bleu_scores ([[x]],[y]) for x, y in zip(df['text_split'], df['all_text_split'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6a9ed2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bleu_sim_1</th>\n",
       "      <th>bleu_sim_1</th>\n",
       "      <th>bleu_sim_1</th>\n",
       "      <th>bleu_sim_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.48</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10540</th>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10541</th>\n",
       "      <td>0.13</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10542</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10543</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10544</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10545 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       bleu_sim_1  bleu_sim_1  bleu_sim_1  bleu_sim_1\n",
       "0            0.40        0.40        0.40        0.40\n",
       "1            0.40        0.40        0.40        0.40\n",
       "2            0.48        0.48        0.48        0.48\n",
       "3            0.95        0.95        0.95        0.95\n",
       "4            0.06        0.06        0.06        0.06\n",
       "...           ...         ...         ...         ...\n",
       "10540        0.09        0.09        0.09        0.09\n",
       "10541        0.13        0.13        0.13        0.13\n",
       "10542        0.02        0.02        0.02        0.02\n",
       "10543        0.40        0.40        0.40        0.40\n",
       "10544        0.72        0.72        0.72        0.72\n",
       "\n",
       "[10545 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " df[['bleu_sim_1','bleu_sim_1','bleu_sim_1','bleu_sim_1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5acb47f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3271094500412624"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"ecu_similarity\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1972913b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.835243231441048"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"cos_similarity\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db8ca37c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26598446286693395"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"jacc_similarity\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6292c4fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31618966334755805"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"bleu_sim_1\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd88e664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "all_datasets= []\n",
    "SIM_COFFICIENTS_THRESHOLDS = {'ECU': df[\"ecu_similarity\"].mean(), 'COS':df[\"cos_similarity\"].mean(), 'JAC':df[\"jacc_similarity\"].mean(), 'BLEU':df[\"bleu_sim_1\"].mean()}\n",
    "LABEL_TO_AUGMENT = ['positive', 'negative']\n",
    "DATA_COLUMN = \"text\"\n",
    "LABEL_COLUMN = \"label\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "722bdb44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ECU': 0.3271094500412624,\n",
       " 'COS': 0.835243231441048,\n",
       " 'JAC': 0.26598446286693395,\n",
       " 'BLEU': 0.31618966334755805}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SIM_COFFICIENTS_THRESHOLDS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d906b879",
   "metadata": {},
   "source": [
    "### Augmentation (All-Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c653b89d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All text augmentation is started... \n",
      "All text augmentation is finished ... \n"
     ]
    }
   ],
   "source": [
    "EcuDF = pd.DataFrame()\n",
    "CosDF = pd.DataFrame()\n",
    "JacDF = pd.DataFrame()\n",
    "BleDF = pd.DataFrame()\n",
    "cntr = 1\n",
    "\n",
    "print('All text augmentation is started... ')\n",
    "for index, row in df.iterrows():         \n",
    "    tmpDF = { 'text': row[DATA_COLUMN], 'label': row[LABEL_COLUMN]}\n",
    "    Ecu_value = row['ecu_similarity']\n",
    "    Cos_value = row['cos_similarity']\n",
    "    Jac_value = row['jacc_similarity']\n",
    "    Bleu_value = row['bleu_sim_1']\n",
    "    \n",
    "    EcuDF = EcuDF.append(tmpDF, ignore_index = True)\n",
    "    CosDF = CosDF.append(tmpDF, ignore_index = True)\n",
    "    JacDF = JacDF.append(tmpDF, ignore_index = True)\n",
    "    BleDF = BleDF.append(tmpDF, ignore_index=True)\n",
    "    \n",
    "    tmpDF = { 'text': row['all_text'], 'label': row[LABEL_COLUMN]}\n",
    "    # Check similarity \n",
    "    if check_similarity_cofficient (Ecu_value, row[LABEL_COLUMN], 'ecu'):\n",
    "        EcuDF = EcuDF.append(tmpDF, ignore_index = True)\n",
    "    \n",
    "    if check_similarity_cofficient (Cos_value, row[LABEL_COLUMN], 'cos'):\n",
    "        CosDF = CosDF.append(tmpDF, ignore_index = True)\n",
    "    \n",
    "    if check_similarity_cofficient (Jac_value, row[LABEL_COLUMN], 'jac'):\n",
    "        JacDF = JacDF.append(tmpDF, ignore_index = True)\n",
    "    \n",
    "    if check_similarity_cofficient (Bleu_value, row[LABEL_COLUMN], 'bleu'):\n",
    "        BleDF = BleDF.append(tmpDF, ignore_index = True)\n",
    "        \n",
    "print('All text augmentation is finished ... ')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83d12cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export dataset\n",
    "EcuDF.to_excel( \"Augmented-Dataset/All/\"+datasetname+\"-Augmented-ECU-ALL-Text-Final.xlsx\", encoding='utf-8', index=False)\n",
    "CosDF.to_excel( \"Augmented-Dataset/All/\"+datasetname+\"-Augmented-COS-ALL-Text-Final.xlsx\", encoding='utf-8', index=False)\n",
    "JacDF.to_excel( \"Augmented-Dataset/All/\"+datasetname+\"-Augmented-JAC-ALL-Text-Final.xlsx\", encoding='utf-8', index=False)\n",
    "BleDF.to_excel( \"Augmented-Dataset/All/\"+datasetname+\"-Augmented-BLE-ALL-Text-Final.xlsx\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52ee996d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel( \"Augmented-Dataset/xls/ArSarcasm-Unbalanced-Augmented-aragpt2-base.xlsx\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfee97e",
   "metadata": {},
   "source": [
    "### Augmentation (New-Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93a9fff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new text augmentation is started... \n",
      "new text augmentation is finished ... \n"
     ]
    }
   ],
   "source": [
    "EcuDF = pd.DataFrame()\n",
    "CosDF = pd.DataFrame()\n",
    "JacDF = pd.DataFrame()\n",
    "BleDF = pd.DataFrame()\n",
    "cntr = 1\n",
    "\n",
    "print('new text augmentation is started... ')\n",
    "for index, row in df.iterrows():         \n",
    "    tmpDF = { 'text': row[DATA_COLUMN], 'label': row[LABEL_COLUMN]}\n",
    "    Ecu_value = row['ecu_similarity']\n",
    "    Cos_value = row['cos_similarity']\n",
    "    Jac_value = row['jacc_similarity']\n",
    "    Bleu_value = row['bleu_sim_1']\n",
    "    \n",
    "    EcuDF = EcuDF.append(tmpDF, ignore_index = True)\n",
    "    CosDF = CosDF.append(tmpDF, ignore_index = True)\n",
    "    JacDF = JacDF.append(tmpDF, ignore_index = True)\n",
    "    BleDF = BleDF.append(tmpDF, ignore_index=True)\n",
    "    \n",
    "    tmpDF = { 'text': row['new_text'], 'label': row[LABEL_COLUMN]}\n",
    "    # Check similarity \n",
    "    if check_similarity_cofficient (Ecu_value, row[LABEL_COLUMN], 'ecu'):\n",
    "        EcuDF = EcuDF.append(tmpDF, ignore_index = True)\n",
    "    \n",
    "    if check_similarity_cofficient (Cos_value, row[LABEL_COLUMN], 'cos'):\n",
    "        CosDF = CosDF.append(tmpDF, ignore_index = True)\n",
    "    \n",
    "    if check_similarity_cofficient (Jac_value, row[LABEL_COLUMN], 'jac'):\n",
    "        JacDF = JacDF.append(tmpDF, ignore_index = True)\n",
    "    \n",
    "    if check_similarity_cofficient (Bleu_value, row[LABEL_COLUMN], 'bleu'):\n",
    "        BleDF = BleDF.append(tmpDF, ignore_index = True)\n",
    "        \n",
    "print('new text augmentation is finished ... ')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d220ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export dataset\n",
    "EcuDF.to_excel( \"Augmented-Dataset/New/\"+datasetname+\"-Augmented-ECU-New-Text-Final.xlsx\", encoding='utf-8', index=False)\n",
    "CosDF.to_excel( \"Augmented-Dataset/New/\"+datasetname+\"-Augmented-COS-New-Text-Final.xlsx\", encoding='utf-8', index=False)\n",
    "JacDF.to_excel( \"Augmented-Dataset/New/\"+datasetname+\"-Augmented-JAC-New-Text-Final.xlsx\", encoding='utf-8', index=False)\n",
    "BleDF.to_excel( \"Augmented-Dataset/New/\"+datasetname+\"-Augmented-BLE-New-Text-Final.xlsx\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21de3478",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
