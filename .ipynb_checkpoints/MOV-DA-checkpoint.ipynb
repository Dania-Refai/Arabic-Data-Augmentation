{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b739c21f",
   "metadata": {},
   "source": [
    " \n",
    "<img width=\"200px\" height=\"200px\" src='logo-en.png'/>\n",
    "\n",
    "<br/>\n",
    "<div style=\"text-align: center; font-size:20px; font-weight:bold; color: #212F3D\">King Abdullah I School of Graduate Studies and Scientific Research</div><br/>\n",
    "<div style=\"text-align: center; font-size:20px; font-weight:bold; color: #212F3D;\">Data Augmentation using Transformers and Similarity Measures for Improving Arabic Text Classification</div><br/>\n",
    "<div style=\"text-align: center; font-size:14px; font-weight:bold; color: #212F3D\">Dania Refai<sup>1</sup>, Saleh Abu-Soud<sup>2</sup>, Mohammad Abdel-Rahman<sup>3</sup></div>\n",
    "<br/>\n",
    "<div style=\"text-align: left; font-size:14px; font-weight:normal; color: #212F3D\">\n",
    "    <sup>1</sup> Department of Computer Science, Princess Sumaya University for Technology (PSUT), Amman, Jordan</div>\n",
    "<br/>\n",
    "<div style=\"text-align: left; font-size:14px; font-weight:normal; color: #212F3D\">\n",
    "    <sup>2</sup> Department of Data Science, Princess Sumaya University for Technology (PSUT), Amman, Jordan</div>\n",
    "<br/>\n",
    "<div style=\"text-align: left; font-size:14px; font-weight:normal; color: #212F3D\">\n",
    "    <sup>3</sup> Department of Data Science, Princess Sumaya University for Technology (PSUT), Amman, Jordan</div>\n",
    "<br/>\n",
    "\n",
    "<div style=\"text-align: left; font-size:14px; font-weight:bold; color: #212F3D\">\n",
    "        Crosspending author: Dania Refai (<span style=\"text-align: left; font-size:16px; font-weight:bold; color: #6495ED\">Dania.Refai@hotmail.com</span>).\n",
    "</div>\n",
    "<br/>\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa9f8c2",
   "metadata": {},
   "source": [
    "### <span style=\"text-align: left; font-size:20px; font-weight:bold; color: #C70039\">General Notes and Directions</span> ###\n",
    "<hr/>\n",
    "\n",
    "> <li style=\"text-align: left; font-size:14px; font-weight:bold; color: #212F3D\">&nbsp;Make sure you have pytorch installed on your machine. Moreover, if you want more information please refer to <a href=\"https://pytorch.org/\">INSTALL PYTORCH</a> from their official website.</li>\n",
    "> <li style=\"text-align: left; font-size:14px; font-weight:bold; color: #212F3D\">&nbsp;Make sure your installed python version is 3.8</li>\n",
    "> <li style=\"text-align: left; font-size:14px; font-weight:bold; color: #212F3D\">&nbsp;Make sure you are running the commands INSIDE source code directory (<span style=\"color: #C70039\">.\\Implementation\\</span>)</li>\n",
    "> <li style=\"text-align: left; font-size:14px; font-weight:bold; color: #212F3D\">&nbsp;Run the following commands in your command shell to create and activate a Virtualenv (<span style=\"color: #C70039\">Windows based systems</span>):</li>\n",
    "> <ol>    \n",
    "> <li style=\"text-align: left; font-family:console; font-size:14px; font-weight:bold; color: #212F3D; list-style-type: none;\">\n",
    "       <span style=\"color: #C70039\">cmd&gt;</span> set PATH=C:\\Users\\(<span style=\"text-align: left; font-size:14px; font-weight:bold; color: #C70039\">-windows_user-</span>)\\AppData\\Local\\Programs\\Python\\Python38\\\n",
    "    </li>\n",
    "> <li style=\"text-align: left; font-family:console; font-size:14px; font-weight:bold; color: #212F3D; list-style-type: none;\">\n",
    "       <span style=\"color: #C70039\">cmd&gt;</span> %PATH%\\python.exe -m pip install --upgrade pip\n",
    "    </li>   \n",
    "> <li style=\"text-align: left; font-family:console; font-size:14px; font-weight:bold; color: #212F3D; list-style-type: none;\">\n",
    "       <span style=\"color: #C70039\">cmd&gt;</span> %PATH%python.exe %PATH%Scripts\\pip.exe install virtualenv \n",
    "    </li>    \n",
    "> <li style=\"text-align: left; font-family:console; font-size:14px; font-weight:bold; color: #212F3D; list-style-type: none;\">\n",
    "       <span style=\"color: #C70039\">cmd&gt;</span> %PATH%\\python.exe -m virtualenv venv \n",
    "    </li>\n",
    "> </ol>\n",
    "> <li style=\"text-align: left; font-size:14px; font-weight:bold; color: #212F3D\">&nbsp; Activate the virtual environment: </li>\n",
    "> <ol>    \n",
    "> <li style=\"text-align: left; font-family:console; font-size:14px; font-weight:bold; color: #212F3D; list-style-type: none;\">\n",
    "       <span style=\"color: #C70039\">cmd&gt;</span> .\\venv\\Scripts\\activate\n",
    "    </li>  \n",
    "> </ol>\n",
    "> <li style=\"text-align: left; font-size:14px; font-weight:bold; color: #212F3D\">&nbsp; Install requirements:</li>\n",
    "> <ol>    \n",
    "> <li style=\"text-align: left; font-family:console; font-size:14px; font-weight:bold; color: #212F3D; list-style-type: none;\">\n",
    "       <span style=\"color: #C70039\">cmd&gt;</span> .\\venv\\Scripts\\pip3 install python-dotenv\n",
    "    </li>\n",
    "> <li style=\"text-align: left; font-family:console; font-size:14px; font-weight:bold; color: #212F3D; list-style-type: none;\">\n",
    "       <span style=\"color: #C70039\">cmd&gt;</span> .\\venv\\Scripts\\pip3 install -r requirements.txt\n",
    "    </li>   \n",
    "> </ol>\n",
    "\n",
    "> <li style=\"text-align: left; font-size:14px; font-weight:bold; color: #212F3D\">&nbsp;Notebook Purpose: <span style=\"color: #C70039\">Data Augmentation for MOV dataset.</span></li>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36182870",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a305f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5b3014",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61de9b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bleu_scores(references, hypotheses):\n",
    "    \"\"\"\n",
    "    Calculates BLEU 1-4 scores based on NLTK functionality\n",
    "\n",
    "    Args:\n",
    "        references: List of reference sentences\n",
    "        hypotheses: List of generated sentences\n",
    "\n",
    "    Returns:\n",
    "        bleu_1, bleu_2, bleu_3, bleu_4: BLEU scores\n",
    "\n",
    "    \"\"\"\n",
    "    #return len(references), len(hypotheses)\n",
    "    bleu_1 = np.round(corpus_bleu(references, hypotheses, weights=(1.0, 0., 0., 0.)), decimals=2)\n",
    "    bleu_2 = np.round(corpus_bleu(references, hypotheses, weights=(0.50, 0.50, 0., 0.)), decimals=2)\n",
    "    bleu_3 = np.round(corpus_bleu(references, hypotheses, weights=(0.34, 0.33, 0.33, 0.)), decimals=2)\n",
    "    bleu_4 = np.round(corpus_bleu(references, hypotheses, weights=(0.25, 0.25, 0.25, 0.25)), decimals=2)\n",
    "    return bleu_1, bleu_2, bleu_3, bleu_4 \n",
    "\n",
    "# Functions\n",
    "def check_label (label):\n",
    "    for lbl in LABEL_TO_AUGMENT:\n",
    "        if lbl.upper() == label.upper():\n",
    "            return True\n",
    "    return False        \n",
    "\n",
    "def check_similarity_cofficient (given_value, label, current_sim_coff):\n",
    "    if not check_label(label):\n",
    "        return False\n",
    "    else:\n",
    "        try:\n",
    "            v = float(given_value)\n",
    "            if float(SIM_COFFICIENTS_THRESHOLDS[current_sim_coff.upper()]) >= v:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        except:\n",
    "            print('exception')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7870c2",
   "metadata": {},
   "source": [
    "### Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d174e3dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>new_text</th>\n",
       "      <th>all_text</th>\n",
       "      <th>original_embbedding</th>\n",
       "      <th>new_embbedding</th>\n",
       "      <th>ecu_similarity</th>\n",
       "      <th>cos_similarity</th>\n",
       "      <th>jacc_similarity</th>\n",
       "      <th>text_split</th>\n",
       "      <th>all_text_split</th>\n",
       "      <th>new_text_split</th>\n",
       "      <th>bleu_sim_1</th>\n",
       "      <th>bleu_sim_2</th>\n",
       "      <th>bleu_sim_3</th>\n",
       "      <th>bleu_sim_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>عظماء ولكن في أشياء كتير أوي ممكن تخلي أي فيلم...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>عظماء ولكن في أشياء كتير أوي ممكن تخلي أي فيلم...</td>\n",
       "      <td>0.023597183,0.01086875,-0.03102856,-0.03223265...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.023597</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['عظماء', 'ولكن', 'في', 'أشياء', 'كتير', 'أوي'...</td>\n",
       "      <td>['عظماء', 'ولكن', 'في', 'أشياء', 'كتير', 'أوي'...</td>\n",
       "      <td>['nan']</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>حقا انه افضل افلام السينما المصرية فى البداية ...</td>\n",
       "      <td>POS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>حقا انه افضل افلام السينما المصرية فى البداية ...</td>\n",
       "      <td>0.030677188,0.040905435,-0.031328138,-0.030169...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.030677</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['حقا', 'انه', 'افضل', 'افلام', 'السينما', 'ال...</td>\n",
       "      <td>['حقا', 'انه', 'افضل', 'افلام', 'السينما', 'ال...</td>\n",
       "      <td>['nan']</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>كبت وحرمان وغيرة بعيدا عن تصوير حالات وقضايا ا...</td>\n",
       "      <td>POS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>كبت وحرمان وغيرة بعيدا عن تصوير حالات وقضايا ا...</td>\n",
       "      <td>0.014913844,0.027157936,-0.030840687,-0.023250...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014914</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['كبت', 'وحرمان', 'وغيرة', 'بعيدا', 'عن', 'تصو...</td>\n",
       "      <td>['كبت', 'وحرمان', 'وغيرة', 'بعيدا', 'عن', 'تصو...</td>\n",
       "      <td>['nan']</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>المومياء...يوم ان يُحصى الابداع! هناك فى مجال ...</td>\n",
       "      <td>POS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>المومياء . . يوم ان يحصى الابداع ! هناك فى مجا...</td>\n",
       "      <td>0.036414325,0.028412146,-0.037543822,-0.037372...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.036414</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['المومياء...يوم', 'ان', 'يُحصى', 'الابداع!', ...</td>\n",
       "      <td>['المومياء', '.', '.', 'يوم', 'ان', 'يحصى', 'ا...</td>\n",
       "      <td>['nan']</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>مفيش جديد للاسف فى اوائل حلقات مسلسل الصفعة اش...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>مفيش جديد للاسف فى اوائل حلقات مسلسل الصفعة اش...</td>\n",
       "      <td>0.026780926,0.009709039,-0.030822175,-0.033138...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.026781</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['مفيش', 'جديد', 'للاسف', 'فى', 'اوائل', 'حلقا...</td>\n",
       "      <td>['مفيش', 'جديد', 'للاسف', 'فى', 'اوائل', 'حلقا...</td>\n",
       "      <td>['nan']</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label new_text  \\\n",
       "0  عظماء ولكن في أشياء كتير أوي ممكن تخلي أي فيلم...   NEG      NaN   \n",
       "1  حقا انه افضل افلام السينما المصرية فى البداية ...   POS      NaN   \n",
       "2  كبت وحرمان وغيرة بعيدا عن تصوير حالات وقضايا ا...   POS      NaN   \n",
       "3  المومياء...يوم ان يُحصى الابداع! هناك فى مجال ...   POS      NaN   \n",
       "4  مفيش جديد للاسف فى اوائل حلقات مسلسل الصفعة اش...   NEG      NaN   \n",
       "\n",
       "                                            all_text  \\\n",
       "0  عظماء ولكن في أشياء كتير أوي ممكن تخلي أي فيلم...   \n",
       "1  حقا انه افضل افلام السينما المصرية فى البداية ...   \n",
       "2  كبت وحرمان وغيرة بعيدا عن تصوير حالات وقضايا ا...   \n",
       "3  المومياء . . يوم ان يحصى الابداع ! هناك فى مجا...   \n",
       "4  مفيش جديد للاسف فى اوائل حلقات مسلسل الصفعة اش...   \n",
       "\n",
       "                                 original_embbedding new_embbedding  \\\n",
       "0  0.023597183,0.01086875,-0.03102856,-0.03223265...              0   \n",
       "1  0.030677188,0.040905435,-0.031328138,-0.030169...              0   \n",
       "2  0.014913844,0.027157936,-0.030840687,-0.023250...              0   \n",
       "3  0.036414325,0.028412146,-0.037543822,-0.037372...              0   \n",
       "4  0.026780926,0.009709039,-0.030822175,-0.033138...              0   \n",
       "\n",
       "   ecu_similarity  cos_similarity  jacc_similarity  \\\n",
       "0        0.023597             NaN              0.0   \n",
       "1        0.030677             NaN              0.0   \n",
       "2        0.014914             NaN              0.0   \n",
       "3        0.036414             NaN              0.0   \n",
       "4        0.026781             NaN              0.0   \n",
       "\n",
       "                                          text_split  \\\n",
       "0  ['عظماء', 'ولكن', 'في', 'أشياء', 'كتير', 'أوي'...   \n",
       "1  ['حقا', 'انه', 'افضل', 'افلام', 'السينما', 'ال...   \n",
       "2  ['كبت', 'وحرمان', 'وغيرة', 'بعيدا', 'عن', 'تصو...   \n",
       "3  ['المومياء...يوم', 'ان', 'يُحصى', 'الابداع!', ...   \n",
       "4  ['مفيش', 'جديد', 'للاسف', 'فى', 'اوائل', 'حلقا...   \n",
       "\n",
       "                                      all_text_split new_text_split  \\\n",
       "0  ['عظماء', 'ولكن', 'في', 'أشياء', 'كتير', 'أوي'...        ['nan']   \n",
       "1  ['حقا', 'انه', 'افضل', 'افلام', 'السينما', 'ال...        ['nan']   \n",
       "2  ['كبت', 'وحرمان', 'وغيرة', 'بعيدا', 'عن', 'تصو...        ['nan']   \n",
       "3  ['المومياء', '.', '.', 'يوم', 'ان', 'يحصى', 'ا...        ['nan']   \n",
       "4  ['مفيش', 'جديد', 'للاسف', 'فى', 'اوائل', 'حلقا...        ['nan']   \n",
       "\n",
       "   bleu_sim_1  bleu_sim_2  bleu_sim_3  bleu_sim_4  \n",
       "0        0.02        0.01        0.01        0.01  \n",
       "1        0.25        0.23        0.22        0.22  \n",
       "2        0.00        0.00        0.00        0.00  \n",
       "3        0.00        0.00        0.00        0.00  \n",
       "4        0.12        0.11        0.11        0.11  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasetname = 'MOV'\n",
    "datasetpath = \"datasets/xls/MOV-Augmented-aragpt2-base.csv\"\n",
    "df = pd.read_csv( datasetpath, sep=\"\\t\", encoding='utf-8')\n",
    "df.columns = ['text', 'label', 'new_text', 'all_text', 'original_embbedding', 'new_embbedding', 'ecu_similarity', 'cos_similarity', 'jacc_similarity','text_split', 'all_text_split', 'new_text_split', 'bleu_sim_1','bleu_sim_2', 'bleu_sim_3', 'bleu_sim_4'] \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0899ad97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "POS        966\n",
       "NEG        381\n",
       "NEUTRAL    170\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c6c0f2",
   "metadata": {},
   "source": [
    "### Calculating Similarity Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e5c01fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_split'] = [list(x.split()) for x in df['text']]\n",
    "df['all_text_split'] = [x.split() for x in df['all_text']]\n",
    "df['new_text_split'] = [str(x).split() for x in df['new_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cdddcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    " df[['bleu_sim_1','bleu_sim_2','bleu_sim_3','bleu_sim_4']] = [ calculate_bleu_scores ([[x]],[y]) for x, y in zip(df['text_split'], df['all_text_split'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6a9ed2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bleu_sim_1</th>\n",
       "      <th>bleu_sim_1</th>\n",
       "      <th>bleu_sim_1</th>\n",
       "      <th>bleu_sim_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1513</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1514</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1515</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1516</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1517 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      bleu_sim_1  bleu_sim_1  bleu_sim_1  bleu_sim_1\n",
       "0           0.02        0.02        0.02        0.02\n",
       "1           0.25        0.25        0.25        0.25\n",
       "2           0.00        0.00        0.00        0.00\n",
       "3           0.00        0.00        0.00        0.00\n",
       "4           0.12        0.12        0.12        0.12\n",
       "...          ...         ...         ...         ...\n",
       "1512        0.01        0.01        0.01        0.01\n",
       "1513        0.00        0.00        0.00        0.00\n",
       "1514        0.01        0.01        0.01        0.01\n",
       "1515        0.25        0.25        0.25        0.25\n",
       "1516        0.00        0.00        0.00        0.00\n",
       "\n",
       "[1517 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " df[['bleu_sim_1','bleu_sim_1','bleu_sim_1','bleu_sim_1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5acb47f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02876978764593484"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"ecu_similarity\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1972913b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.904"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"cos_similarity\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db8ca37c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00039139749505603163"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"jacc_similarity\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6292c4fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07152274225444957"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"bleu_sim_1\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd88e664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "all_datasets= []\n",
    "SIM_COFFICIENTS_THRESHOLDS = {'ECU': df[\"ecu_similarity\"].mean(), 'COS':df[\"cos_similarity\"].mean(), 'JAC':df[\"jacc_similarity\"].mean(), 'BLEU':df[\"bleu_sim_1\"].mean()}\n",
    "LABEL_TO_AUGMENT = ['NEG', 'NEUTRAL']\n",
    "DATA_COLUMN = \"text\"\n",
    "LABEL_COLUMN = \"label\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "722bdb44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ECU': 0.02876978764593484,\n",
       " 'COS': 0.904,\n",
       " 'JAC': 0.00039139749505603163,\n",
       " 'BLEU': 0.07152274225444957}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SIM_COFFICIENTS_THRESHOLDS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575ff546",
   "metadata": {},
   "source": [
    "### Augmentation (All-Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c653b89d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All text augmentation is started... \n",
      "All text augmentation is finished ... \n"
     ]
    }
   ],
   "source": [
    "EcuDF = pd.DataFrame()\n",
    "CosDF = pd.DataFrame()\n",
    "JacDF = pd.DataFrame()\n",
    "BleDF = pd.DataFrame()\n",
    "cntr = 1\n",
    "\n",
    "print('All text augmentation is started... ')\n",
    "for index, row in df.iterrows():         \n",
    "    tmpDF = pd.DataFrame({'text': [row[DATA_COLUMN]], 'label': [row[LABEL_COLUMN]]})\n",
    "    Ecu_value = row['ecu_similarity']\n",
    "    Cos_value = row['cos_similarity']\n",
    "    Jac_value = row['jacc_similarity']\n",
    "    Bleu_value = row['bleu_sim_1']\n",
    "    \n",
    "    EcuDF = pd.concat([EcuDF, tmpDF], ignore_index=True)\n",
    "    CosDF = pd.concat([CosDF, tmpDF], ignore_index=True)\n",
    "    JacDF = pd.concat([JacDF, tmpDF], ignore_index=True)\n",
    "    BleDF = pd.concat([BleDF, tmpDF], ignore_index=True)\n",
    "    \n",
    "    tmpDF = pd.DataFrame({'text': [row['all_text']], 'label': [row[LABEL_COLUMN]]})\n",
    "    # Check similarity\n",
    "    if check_similarity_cofficient(Ecu_value, row[LABEL_COLUMN], 'ecu'):\n",
    "        EcuDF = pd.concat([EcuDF, tmpDF], ignore_index=True)\n",
    "\n",
    "    if check_similarity_cofficient(Cos_value, row[LABEL_COLUMN], 'cos'):\n",
    "        CosDF = pd.concat([CosDF, tmpDF], ignore_index=True)\n",
    "\n",
    "    if check_similarity_cofficient(Jac_value, row[LABEL_COLUMN], 'jac'):\n",
    "        JacDF = pd.concat([JacDF, tmpDF], ignore_index=True)\n",
    "\n",
    "    if check_similarity_cofficient(Bleu_value, row[LABEL_COLUMN], 'bleu'):\n",
    "        BleDF = pd.concat([BleDF, tmpDF], ignore_index=True)\n",
    "        \n",
    "print('All text augmentation is finished ... ')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83d12cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Export dataset\n",
    "EcuDF.to_excel(\"Augmented-Dataset/all/\"+datasetname+\"-ECU-All-Text-Final.xlsx\", index=False)\n",
    "CosDF.to_excel(\"Augmented-Dataset/all/\"+datasetname+\"-COS-All-Text-Final.xlsx\", index=False)\n",
    "JacDF.to_excel(\"Augmented-Dataset/all/\"+datasetname+\"-JAC-All-Text-Final.xlsx\", index=False)\n",
    "BleDF.to_excel(\"Augmented-Dataset/all/\"+datasetname+\"-BLE-All-Text-Final.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52ee996d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"Augmented-Dataset/xls/MOV-Augmented-aragpt2-base.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6efe4ce",
   "metadata": {},
   "source": [
    "### Augmentation (New-Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93a9fff2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new text augmentation is started... \n",
      "new text augmentation is finished ... \n"
     ]
    }
   ],
   "source": [
    "EcuDF = pd.DataFrame()\n",
    "CosDF = pd.DataFrame()\n",
    "JacDF = pd.DataFrame()\n",
    "BleDF = pd.DataFrame()\n",
    "cntr = 1\n",
    "\n",
    "print('new text augmentation is started... ')\n",
    "for index, row in df.iterrows():         \n",
    "    tmpDF = { 'text': row[DATA_COLUMN], 'label': row[LABEL_COLUMN]}\n",
    "    Ecu_value = row['ecu_similarity']\n",
    "    Cos_value = row['cos_similarity']\n",
    "    Jac_value = row['jacc_similarity']\n",
    "    Bleu_value = row['bleu_sim_1']\n",
    "    \n",
    "    EcuDF = pd.concat([EcuDF, pd.DataFrame(tmpDF, index=[0])], ignore_index=True)\n",
    "    CosDF = pd.concat([CosDF, pd.DataFrame(tmpDF, index=[0])], ignore_index=True)\n",
    "    JacDF = pd.concat([JacDF, pd.DataFrame(tmpDF, index=[0])], ignore_index=True)\n",
    "    BleDF = pd.concat([BleDF, pd.DataFrame(tmpDF, index=[0])], ignore_index=True)\n",
    "    \n",
    "    tmpDF = { 'text': row['new_text'], 'label': row[LABEL_COLUMN]}\n",
    "    # Check similarity \n",
    "    if check_similarity_cofficient (Ecu_value, row[LABEL_COLUMN], 'ecu'):\n",
    "        EcuDF = pd.concat([EcuDF, pd.DataFrame(tmpDF, index=[0])], ignore_index=True)\n",
    "    \n",
    "    if check_similarity_cofficient (Cos_value, row[LABEL_COLUMN], 'cos'):\n",
    "        CosDF = pd.concat([CosDF, pd.DataFrame(tmpDF, index=[0])], ignore_index=True)\n",
    "    \n",
    "    if check_similarity_cofficient (Jac_value, row[LABEL_COLUMN], 'jac'):\n",
    "        JacDF = pd.concat([JacDF, pd.DataFrame(tmpDF, index=[0])], ignore_index=True)\n",
    "    \n",
    "    if check_similarity_cofficient (Bleu_value, row[LABEL_COLUMN], 'bleu'):\n",
    "        BleDF = pd.concat([BleDF, pd.DataFrame(tmpDF, index=[0])], ignore_index=True)\n",
    "        \n",
    "print('new text augmentation is finished ... ')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d220ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export dataset\n",
    "EcuDF.to_excel(\"Augmented-Dataset/New/\"+datasetname+\"-ECU-New-Text-Final.xlsx\",encoding='utf-8', index=False)\n",
    "CosDF.to_excel(\"Augmented-Dataset/New/\"+datasetname+\"-COS-New-Text-Final.xlsx\",encoding='utf-8', index=False)\n",
    "JacDF.to_excel(\"Augmented-Dataset/New/\"+datasetname+\"-JAC-New-Text-Final.xlsx\",encoding='utf-8', index=False)\n",
    "BleDF.to_excel(\"Augmented-Dataset/New/\"+datasetname+\"-BLE-New-Text-Final.xlsx\",encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
